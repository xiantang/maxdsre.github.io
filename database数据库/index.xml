<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Database(数据库)s on xiantang</title>
    <link>https://xiantang.github.io/database%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
    <description>Recent content in Database(数据库)s on xiantang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://xiantang.github.io/database%E6%95%B0%E6%8D%AE%E5%BA%93/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://xiantang.github.io/database%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xiantang.github.io/database%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/</guid>
      <description>索引的类型: B-Tree 索引 InnoDB 使用的是B+Tree
根节点的槽中存放了指向子节点的指针，存储引擎根据这些指针向下查找。通过要查找的值来找到合适的指针进入下层节点。
假设有如下数据表
create table people( last_name varchar(50) not null, first_name varchar(50) not null, dob date not null, gender enum(&amp;#39;m&amp;#39;,&amp;#39;f&amp;#39;) not null, key(last_name,first_name,dob) ); 对于表中的每一行数据，索引中包含了last_name,first_name 和 dob 列的值。 显示了该索引是如何组织数据存储的。
有效使用索引：
 全值匹配 匹配最左前缀 匹配列前缀 匹配范围值 精确匹配某一列并范围匹配另外一列 值访问索引  B-Tree 索引的限制：
 如果不是按照索引的最左侧开始查找，就无法使用索引。 不能跳过索引中的列，如果要查找姓名为 A 生日在 B 的人是只能使用索引的第一列。  B-树  内部节点:含有与页相关联的页的副本 外部节点:含有指向实际数据的引用 哨兵键:小于其他所有键，一开始B-树只含有
一个根节点，节点初始化出的就是哨兵节点  查找和插入 查找:在可能含有被查找键的唯一子树中进行一次递归的
搜索
插入: 如果被插入的节点变成一个溢出的节点
递归调用不断向上调用分裂溢出的节点
为什么使用B-Tree / B+Tree 主要和硬盘的存取原理有关。 硬盘不是按需读取的，每次读取都会预读一些。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://xiantang.github.io/database%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xiantang.github.io/database%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis/</guid>
      <description>安装redis 创建redis目录 mkdir redis
安装wget yum install -y wget
设置登陆密码 这是修改redis的配置文件 vim /etc/redis/redis.conf
找到requirepass
修改密码。
重启redis
/etc/init.d/redis-server restart
scrapy爬虫报错 2018-12-23 14:03:12 [twisted] CRITICAL: Unhandled Error Traceback (most recent call last): File &amp;#34;/home/ubuntu/.local/lib/python3.5/site-packages/scrapy/commands/crawl.py&amp;#34;, line 58, in run self.crawler_process.start() File &amp;#34;/home/ubuntu/.local/lib/python3.5/site-packages/scrapy/crawler.py&amp;#34;, line 291, in start reactor.run(installSignalHandlers=False) # blocking call File &amp;#34;/home/ubuntu/.local/lib/python3.5/site-packages/twisted/internet/base.py&amp;#34;, line 1267, in run self.mainLoop() File &amp;#34;/home/ubuntu/.local/lib/python3.5/site-packages/twisted/internet/base.py&amp;#34;, line 1276, in mainLoop self.runUntilCurrent() --- &amp;lt;exception caught here&amp;gt; --- File &amp;#34;/home/ubuntu/.local/lib/python3.5/site-packages/twisted/internet/base.py&amp;#34;, line 902, in runUntilCurrent call.</description>
    </item>
    
  </channel>
</rss>